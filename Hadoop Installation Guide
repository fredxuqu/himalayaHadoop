Hadoop的环境搭建
	ubuntu14
	Hadoop2.7.6
	JDK1.8

	a.	设置网络为ANT模式
	b.	克隆虚拟机
	c.	在/etc/sudoers中将普通用户加入sudo
		fred ALL=(ALL) ALL

	d.	修改/etc/hostname，修改主机的名称，与节点名称一致（node1，node2，node3等，根据机器的配置而定）

	e.	修改/etc/hosts文件，必须注释掉 127.0.0.1 ubuntu这一行
		127.0.0.1       localhost
		#127.0.0.1       node101
		192.168.179.101 node101
		192.168.179.102 node102
		192.168.179.103 node103
		192.168.179.104 node104
		192.168.179.105 node105
	
	f.	修改/etc/network/interfaces，配置静态IP
		auto eth0
		iface eth0 inet static
		address 192.168.179.101
		netmask 255.255.255.0
		gateway 192.168.179.2
		broadcast 192.168.179.255
		dns-nameserver 114.114.114.114

	g.	修改/etc/reslov.conf，配置DNS，使用电信的DNS服务器114.114.114.114
		nameserver 8.8.8.8
		nameserver 114.114.114.114

	h.	重启networking
		/etc/init.d/networking restart

	i.	修改主机名
		hostname 
		vi /etc/hostname

	j.	关闭防火墙
		ufw status/disable/enable

	k.	在/opt 下创建目录
		mkdir module
		mkdir software
		chown fred:fred /module /software

	l.	安装JDK
		下载： http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz
		解压 tar -xvf jdk-8u181-linux-x64.tar.gz 
		配置环境变量  vi /etc/profile
		export JAVA_HOME=/usr/local/java
		export PATH=$PATH:$JAVA_HOME/bin
		
	m.	安装zookeeper	
		下载 zookeeper-3.4.8.tar.gz
		解压
		配置zoo.cfg
			tickTime=2000
			initLimit=10
			syncLimit=5
			dataDir=/opt/workspaces/zookeeper/data
			clientPort=2181
			server.1=node101:2888:3888
			server.2=node102:2888:3888
			server.3=node103:2888:3888
			
		修改zkEnv.sh，修改里面的日志文件位置
		
		配置zookeeper的环境变量
			export ZK_HOME=/opt/workspaces/zookeeper
			export PATH=$PATH:$ZK_HOME/bin
		
		启停zookeeper服务，查看节点状态
		zkServer.sh start/stop/status
		
	Hadoop集群
		1.	下载：http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz
		解压：tar -xvf hadoop-2.7.6.tar.gz 
		配置hadoop-env.sh，修改JAVA_HOME

		2.	添加Hadoop环境变量
		export HADOOP_HOME=/opt/workspaces/hadoop
		export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
		
		创建输入文件的目录
		mkdir /opt/workspaces/hadoop/input
		cp /opt/workspaces/hadoop/etc/hadoop/*.xml /opt/workspaces/hadoop/input
		
		使用官方提供的测试用例测试：
		/opt/workspaces/hadoop/bin/hadoop jar /opt/workspaces/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar grep input output 'dfs[a-z.]+'
		bin/hadoop jar /opt/workspaces/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount wcinput wcoutput
	
	伪分布式部署（HDFS）
		http://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-common/SingleCluster.html
		1. core-site.xml
			<property>
		        <name>fs.defaultFS</name>
		        <value>hdfs://node100:9000</value>
		    </property>
		    <property>
		        <name>hadoop.tmp.dir</name>
		        <value>/opt/workspaces/hadoop/data/tmp</value>
		    </property>
		2. hdfs-site.xml
			<property>
		        <name>dfs.replication</name>
		        <value>1</value>
		    </property>
		3. format namenode
			bin/hdfs namenode -format
			
		4. 启动namenode
			sbin/hadoop-daemon.sh start namenode
		
		5. 启动datanode
			sbin/hadoop-daemon.sh start datanode
			
		6. 通过web页面查看
			http://192.168.179.100:50070/
			
		7. 创建文件夹
			bin/hdfs dfs -mkdir -p /usr/fred/input
			bin/hdfs dfs -put wcinput/wc.input /usr/fred/input
			
		8. 测试
			bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /usr/fred/input /usr/fred/output
		
		9. 查看运行结果
			bin/hdfs dfs -cat /usr/fred/wcoutput/p*
			
		注意：修改临时目录的时候，需要将hadoop相关的进程全部杀掉，将tmp目录和logs目录内容全部都删除掉，然后再格式化namenode，启动。
			
	伪分布式部署（YARN）
		mapred-site.xml
			<property>
		        <name>mapreduce.framework.name</name>
		        <value>yarn</value>
		    </property>
		
		yarn-site.xml
			<property>
		        <name>yarn.nodemanager.aux-services</name>
		        <value>mapreduce_shuffle</value>
		    </property>
		
		    <property>
		        <name>yarn.resourcemanager.hostname</name>
		        <value>node100</value>
		    </property>
		    
		启动namenode和datanode
			sbin/hadoop-daemon.sh start namenode
			sbin/hadoop-daemon.sh start datanode
			
		启动resourcemanager 和 nodemananger
			sbin/yarn-daemon.sh start resourcemanager
			sbin/yarn-daemon.sh start nodemanager
			
		检验
			http://192.168.179.100:8088
			
		删除output
		
		测试 
			bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /usr/fred/input /usr/fred/output
			
		查看结果
			bin/hdfs dfs -cat /usr/fred/output/p*
			
	配置历史服务器
		修改 mapred-site.xml
			<property>
		        <name>mapreduce.jobhistory.address</name>
		        <value>node100:10020</value>
		    </property>
		    <property>
		        <name>mapreduce.jobhistory.webapp.address</name>
		        <value>node100:19888</value>
		    </property>
		    
		启动historyserver
			sbin/mr-jobhistory-daemon.sh start historyserver
			
	集成日志聚集的功能
		停止掉所有的hadoop进程
		编辑 yarn-site.xml,增加如下配置
			<property>
		        <name>yarn.log-aggregation-enable</name>
		        <value>true</value>
		    </property>
		
		    <property>
		        <name>yarn.log-aggregation.retain-seconds</name>
		        <value>604800</value>
		    </property>
			
			
	完全分布式部署（非HA）
		1. 配置虚拟机
			hosts、主机名称、静态IP地址
		2. 克隆三台虚拟机
		3. 拷贝文件配置
			scp
				scp original/filename.tar.gz remoteUser@remoteIP:/target
			rsync
				rsync -rvl original/filename.tar.gz remoteUser@remoteIP:/target
				
		4. 配置ssh免密登陆
			a. generate private key and public key by
				ssh-keygen -t rsa 
			b. copy public key to remote server by 
				ssh-copy-id -i ~/.ssh/id_rsa.pub fred@node101
			xcall
				ssh fred@remoteIP command
		
		5. 集群规划
					node101				node102				node103
			
			HDFS	NameNode			DataNode			SecondNameNode
					DataNode								DataNode
					
			YARN	NodeManager			NodeManager			NodeManager
										ResourceManager		
										
		6. 配置文件
			core-site.xml
				<property>
			        <name>fs.defaultFS</name>
			        <value>hdfs://node102:9000</value>
			    </property>
			    <property>
			        <name>hadoop.tmp.dir</name>
			        <value>/opt/workspaces/hadoop/data/tmp</value>
			    </property>			
				
			hadoop-env.sh
				config java home
				
			hdfs-site.xml
				<property>
			        <name>dfs.replication</name>
			        <value>3</value>
			    </property>
			    <property>
			        <name>dfs.namenode.secondary.http-address</name>
			        <value>node103:50090</value>
			    </property>
				
			slaves
				node101
				node102
				node103
											
			yarn-env.sh
				config javahome
				
			yarn-site.xml
				<property>
			        <name>yarn.nodemanager.aux-services</name>
			        <value>mapreduce_shuffle</value>
			    </property>
			
			    <property>
			        <name>yarn.resourcemanager.hostname</name>
			        <value>node102</value>
			    </property>
			    
			mapred-env.sh
				
			mapred-site.xml
				<property>
			        <name>mapreduce.framework.name</name>
			        <value>yarn</value>
			    </property>
		7. 格式化namenode（必须在namenode上启动集群）
			bin/hdfs namenode format
			
		8. 启动服务
			在node101 上面执行 sbin/start-dfs.sh 
			在node102 上面执行 sbin/start-yarn.sh
			
		9. 验证
			hadoop fs -mkdir -p /usr/fred/input
			hadoop fs -put wcinput/wc.input /usr/fred/input
				上传的文件放到了 data/tmp/dfs/data/current/BP-1463701452-192.168.179.101-1533539433792/current 目录下面，
			如果一个文件被切分成了多个，可以使用cat命令将多个block压缩到一个文件中，然后解压，得到原始文件。
			hadoop fs -lsr
			
			http://node101:50070/explorer.html#/usr/fred/input
		
		10. 集群时间同步
			安装ntp，采用默认配置
		
		
	编译Hadoop
		1. 下载如下包
			ant
			maven
			hadoop源码
			protobuf
		
		2. 解压，配置环境变量
		
		3. 安装g++ 和 glibc-headers 根据操作系统不同，使用不同的版本，使用apt-get系统会自动选择。
			sudo apt-get install build-essential
			gcc --version
			
			//使用了build-essential之后，可以不用再装g++了。
			sudo apt-get install g++-4.4
			g++ --version
			
		4. 安装make和cmake
			sudo apt-get update
			sudo apt-get install ubuntu-make
			umake --help
			
		5. cd /opt/workspaces/protobuf
			make
			make check
			make install
			idconfig
			
			vi /etc/profile
		
		6. 安装openssl
			sudo apt install cmake
			sudo apt-get install openssl 
			sudo apt-get install libssl-dev
			sudo apt-get install zlib		
			sudo apt-get install libncurses5-dev
			
		8. 解压源码
			tar -xvf hadoop-2.7.6-src.tar.gz -C /opt/workspaces/
			
		9. 编译
			为什么要编译？
				原因在与Hadoop是java写的，但是有很多辅助功能是java之外的一些native方法提供的，这些功能具有平台相关性，根据不同的系统重新编译会减少不必要的错误。
			
			mvn package -Pdist,native -DskipTests -Dtar				//--不生成文档
			mvn package -Pdist,native,docs,src -DskipTests -Dtar 	//生成文档，需要安装findbugs，并设置FINDBUGS_HOME环境变量
			
			常见错误及解决
			[ERROR]  around Ant part ...<exec dir="/usr/local/hadoop-2.7.1-src/hadoop-common-project/hadoop-common/target/native" executable="cmake" failonerror="true">... @ 4:151 in /usr/local/hadoop-2.7.1-src/hadoop-common-project/hadoop-common/target/antrun/build-main.xml
	 		解决：
			yum install cmake
			 
			[ERROR] around Ant part ...<exec dir="/usr/local/hadoop-2.7.1-src/hadoop-tools/hadoop-pipes/target/native" executable="cmake" failonerror="true">... @ 5:131 in /usr/local/hadoop-2.7.1-src/hadoop-tools/hadoop-pipes/target/antrun/build-main.xml
			解决
			yum install openssl-devel
					 
			[ERROR] around Ant part ...<exec dir="/usr/local/hadoop-2.7.1-src/hadoop-common-project/hadoop-common/target/native" executable="cmake" failonerror="true">... @ 4:141 in /usr/local/hadoop-2.7.1-src/hadoop-common-project/hadoop-common/target/antrun/build-main.xml
			解决：
			yum -y install zlib-devel
			yum -y install ncurses-devel
			
			
	
				
			
			
			
									
		5. config zookeeper server
						
		5. Config HDFS High Availability Using the Quorum Journal Manager
			a. hdfs_site.xml
				<property>
				  <name>dfs.nameservices</name>
				  <value>himalaya</value>
				</property>			
				<property>
				  <name>dfs.ha.namenodes.himalaya</name>
				  <value>nn1,nn2</value>
				</property>			
				<property>
				  <name>dfs.namenode.rpc-address.himalaya.nn1</name>
				  <value>node1:8020</value>
				</property>
				<property>
				  <name>dfs.namenode.rpc-address.himalaya.nn2</name>
				  <value>node2:8020</value>
				</property>			
				<property>
				  <name>dfs.namenode.http-address.himalaya.nn1</name>
				  <value>node1:50070</value>
				</property>
				<property>
				  <name>dfs.namenode.http-address.himalaya.nn2</name>
				  <value>node2:50070</value>
				</property>			
				<property>
				  <name>dfs.namenode.shared.edits.dir</name>
				  <value>qjournal://node1:8485;node2:8485;node3:8485/himalaya</value>
				</property>			
				<property>
				  <name>dfs.client.failover.proxy.provider.himalaya</name>
				  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
				</property>			
				<property>
				  <name>dfs.ha.fencing.methods</name>
				  <value>sshfence</value>
				</property>			
				<property>
				  <name>dfs.ha.fencing.ssh.private-key-files</name>
				  <value>/home/fred/.ssh/id_rsa</value>
				</property>			
				<property>
				  <name>dfs.journalnode.edits.dir</name>
				  <value>/home/fred/hadoop/jn/data</value>
				</property>			
				<property>
				  <name>dfs.ha.automatic-failover.enabled</name>
				  <value>true</value>
				</property>
			
			b. core-site.xml
				<property>
				  <name>fs.defaultFS</name>
				  <value>hdfs://himalaya</value>
				</property>			
				<property>
				  <name>ha.zookeeper.quorum</name>
				  <value>node1:2181,node2:2181,node3:2181</value>
				</property>			
				<property>
				  <name>hadoop.tmp.dir</name>
				  <value>/home/fred/hadoop/tmp</value>
				</property>
				
			c. config slaves
				node1
				node2
				node3
				
			d.	if os is ubuntu, change /etc/hosts, comment 127.0.1.1
		
		5. start up all server	
			a.  start zookeeper
				zkServer.sh start
			
			b. 	start hadoop server as journalnode, execute below command on each machine
				hadoop/sbin/hadoop-daemon.sh start journalnode
			
			c. 	format a namenode
				hadoop/bin/hdfs namenode -format
				attention : Please delete all files under hadoop.tmp.dir, /tmp and zookeeper/data/version-2
			
				original file will be found under tmp/dfs/name/current
				
			d.	start a namenode which is formatted.
				sbin/hadoop-daemon.sh start namenode
			
			e.	then execute below command on unformatted namenode server to format namenode
				bin/hdfs namenode -bootstrapStandby
				check tmp/dfs/name/current
				
				start current namenode server
				sbin/hadoop-daemon.sh start namenode
			
			f. 	format zkfc
				hadoop/bin/hdfs zkfc -formatZK
			
			e.	stop all hadoop service
				hadoop/sbin/stop-dfs.sh
			
				if system can't find JAVA_HOME, identify JAVA_HOME in hadoop-env.sh 
			
			f.	start up all service
				hadoop/sbin/start-dfs.sh
				
		6. create hdfs folder and upload file
			./hdfs dfs -mkdir -p /usr/input/temp
			
			./hdfs dfs -put /home/fred/data.txt /usr/input/temp
					
		7.	config mapreduce
			mapred-site.xml		
			<property>
				<name>mapreduce.framework.name</name>
				<value>yarn</value>
			</property>
			
			yarn-site.xml
			<property>
				<name>yarn.nodemanager.hostname</name>
				<value>node1</value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
				<value>org.apache.hadoop.mapred.ShuffleHandler</value>
			</property>
			













	
	
	
	